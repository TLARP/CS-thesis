%% LaTeX source of Chapter 4 of the thesis.
%% NEVER compile this file. Complie 'thesis.tex' instead.

\chapter{时序数据压缩算法和可视化}
\label{Chapter 4}

\section{时序数据压缩算法与实现}
\label{section 4.1}
\subsection{问题描述}
\label{section 4.11}
汽车运行过程中引擎的相关参数我们可以通过传感器获得，例如汽车发动机的转速，汽车的进气量和喷油量。这些数据的维度可以达到100以上，也就是说我们采集到
的数据在数据库当中可以单表达到100列。假设我们的采样频率达到100，可以计算每小时我们采集数据的次数为3600*100.很明显如果汽车长时间运转，这些数据将
对汽车的存储系统造成极大的压力。将这些数据全部存储起来将浪费大量的存储资源，但是如何不加处理的直接丢弃，那么一旦出现汽车故障，我们将不能获取即时有
效的原始数据。

通过我们对时序数据的观测，在这些时序数据中存在大量的数据冗余，原因很直接，因为大部分的数据通常再某段时间都是稳定的，例如引擎稳定运行时的温度，特别
是像汽车的档位这类数据，很有可能长时间不改变，对于日常的业务场景来说，维护人员很难从海量的时序数据中快速找到自己需要的异常数据，因此我们可以允许再
保存的过程中与原始数据有一定的误差，在存储的过程中我们依然采用了关系数据库，这不仅是因为关系数据库的技术成熟，而且目前存在的一些早期的时序数据库的实现原型也是基于关系数据库而来。


时间本身充满了多变性，他可以是一个时间点，也可以是一个时间间隔，既可以是线性的，也可以是周期的。如果咋考虑时序数据的维数，可想而知这样的数据他的复
杂度是相当高的，对于这样的数据，如何可视化也呈现出了多样性，根据特定的时序数据，现在已经存在了一些可视化框架，例如针对模拟数据我们可以采用SimVis，
而针对新闻数据我们可以采用ThemeRiver进行分析。

时序数据可视化从通用的角度来看可以认为是从维度到空间的映射，一般可视化框架有XmdvTool和Visage相对标准的可视化技术，而且平行坐标，复杂坐标都可以用来可视化时序数据，但对于海量的时序数据，这些框架显得捉襟见肘。

对于数据量庞大的时序数据，我们可以选择基于蜡烛图的可视化方法，蜡烛图(candlestick chart)又称k线图，看线图可以容易的表示统计数据中的若干内容，
关于k线图的具体内容请参考背景知识。


\subsection{算法的基本思路}
\label{section 4.12}

我们根据时序数据的维数和设定的压缩比例，对输入的时序数据进行单维处理。在单维数据中我们将无明显波动的数据，合并到相同的区间中，注意在合并的过程中，
同时更新对应区间的时间点，当我们每个区间的数据点数超过了限制之后，我们采用对应的区间合并算法，将每维数据进行区间合并。处理完单维数据之后，我们将
所有维数的数据进行区间合并，来产生对应的最终输出。

如图所示，假设我们采样到的时序数据包含4维，D1～D4，其中我们可以看到D1从t1到t6的值未发生变化，t7到t16区间内的值相同，因此我们将D1划分为[1,6]
[7,16]两个区间，对于D2～D4我们也采用相同的方法，D2和D3将被划分为3个区间[1,6],[7,10],[11,16].同时我们将这几个区间的时间标签提取出来并进行排序
重排后的时序列表对应为[1,6,7,10,11,16]
，然后我们重新生成时序数据，此时共产生了6个时刻对应的6条数据，每个时刻对应的值为该区间的平均值，最后通过压缩后的结果如下图所示。

\subsection{数据区间的定义}
\label{sectoin 4.13}

设D维时序数据的每一分量为D$_{i}$，压缩后的数据点数我们设置为CP(D$_{i}$),并将压缩梯度Grad(D$_{i}$)设置为CP(D$_{i}$)*2$^{k}$(k=1,2,3...)
，定义Max(D$_{i}$)为D$_{i}$已经扫描数据的最小值，Min(D$_{i}$)为D$_{i}$已经扫描过得数据最大值，IL(D$_{i}$)
用于存储已经扫描过的区间列表，列表的每一个区间是一个六元向量：


\begin{equation}
T=<t_{s},t_{e},v_{max},v_{min},v_{avg},n>
\end{equation}


其中t$_{s}$和t$_{e}$分别表示区间的开始时间标签和结束时间标签，v$_{max}$,v$_{min}$,v$_{avg}$分别表示区间类采样值的最大值，最小值，和平均值。
其中n表示所有的数据点数。每个区间是1个以上的原始数据点合并之后的结果，同一个区间覆盖的原始数据点基本平稳，而相邻的区间分隔的时间节点应该对应原始数
据中比较明显的拐点，在压缩的过程中我们在指定的输入条件CP(D$_{i}$)下，不断对D$_{i}$创建区间，扩展区间和合并区间。


\textbf{新建区间CI：}高维度的时序数据再压缩的过程中必须保持原数据总体变化趋势这些基本特征，再数据处理的过程中，当遇到较大的数据奇点且不在约定的梯度等级时，此时我们需要闯将新的区间段，新的区间段取决于奇点数据，也就是：
\begin{equation}
I_{n}=<t,t,d_{it},d_{it},d_{it},1>
\end{equation}
其中d$_{it}$为拐点数据，也就是当前时刻t的第i维的数据值。

\textbf{扩展区间EI:}在扫描数据序列的过程中，若当前数据点d$_{it}$属于当前的数据区间，则应对当前区间进行更新，区间扩展方法为：
\begin{equation}
I_{last}=<t_{s},t,MAX(v_{max},d_{it}),MIN(v_{min},d_{it}),(v_{avg}*n+d_{it})/(n+1),n+1)>
\end{equation}
其中I$_{last}$为IL(D$_{i}$)区间的最后一个元组，d$_{it}$为当前时刻t关于D$_{i}$的分量


\textbf{区间合并MI:}区间合并发生在已有的区间总数超出了设定的数据点数CP(D$_{i}$)时进行，区间合并是指将原来相邻的区间合并为一个区间，设：
\begin{equation}
I_{i}=<t_{s},t_{e},v_{max},v_{min},v_{avg},n>
\end{equation}


\begin{equation}
I_{i+1}=<t_{s}^{'},t_{e}^{'},v_{max}^{'},v_{min}^{'},v_{avg}^{'},n^{'}>
\end{equation}

为数据区间列表中相邻的元组，则合并后数据区间I$_{lr}$:

\begin{equation}
\begin{split}
I_{lf}=<MIN(t_{s},t_{s}^{'}),MAX(t_{e},t_{e}^{'}),MAX(v_{max},v_{max}^{'}),MIN(v_{min},v_{min}^{'})\\
,(v_{avg}*n+v_{avg}^{'}*n^{'})/(n+n^{'}),n+n^{'}>
\end{split}
\end{equation}


\subsection{数据压缩算法}
\label{4.14}
在对整个数据序列进行压缩的过程中，顺序扫描对应的数据，分别对每一分量进行区间压缩算法，得到所有不同分量的区间列表序列IL。在区间的创建和扩展的过程
中，对每个分量D$_{i}$判断IL(D$_{i}$)中的区间个数，和CP(D$_{i}$)的大小，如果|IL(D$_{i}$)|>CP(D$_{i}$)
则按照区间合并操作MI选择性的对相邻区间进行合并，这里的选择性是指选哪些数据，分布较为接近和相似的区间进行合并，最后，取IL中所有的IL(D$_{i}$)
中的元组标签并按时间先后进行排序，将排序好的时间标签，放入标签队列中TL，最终生成分量数据，对应的如下算法：
\newpage


\begin{algorithm}
% enter the algorithm environment
\caption{高维时序数据压缩算法CompressInterval}
% give the algorithm a caption
\label{alg1}
% and a label for \ref{} commands later
\begin{algorithmic}[1]
% enter the algorithmic environment
\REQUIRE 分量压缩点数CP(D$_{i}$)，原始数据序列D 
\ENSURE 压缩后的数据序列
\FOR{($i=1$ to N)}
\STATE Max(D$_{i}$)=0;Min(D$_{i}$)=0;IL(D$_{i}$)=[];
\STATE Grad(D$_{i}$)=CP(D$_{}i$)*k;
\ENDFOR
\WHILE{(未达到输入数据D结束位置，且下一条数据记录为D$_{t}$)}
\STATE 	{\FOR{$i=1$ to $N$}
		\STATE Max(D$_{i}$)=MAX(Max(D$_{i}$),d$_{it}$);
		\STATE Min(D$_{i}$)=MIN(Min(D$_{i}$),d$_{it}$);
		\STATE I$_{last}$=IL(D$_{i}$)的最后一个区间；
		\IF{($ d_{it} \geq I_{last} \times v_{min}  \AND d_{it} \leq I_{last} \times v_{max} )$}
		\STATE $ I_{last} = EI(I_{last},d_{it}) $
		\ELSE  
		\STATE $ IL(D_{i}) push EC(d_{it}) $
		\ENDIF
		\IF{($   |IL(D_{i})|  > CP(D{i})   $)}
		\STATE $ IL(D_{i})=MergeInternal(IL(D_{i}),CP(D_{i}),Grad(D_{i})) $
		\ENDIF
		\ENDFOR
		}
\ENDWHILE
\STATE IL=[$ IL(D_{1}),IL(D_{2}...IL(D_{n}) $];
\RETURN GenData(IL);
\end{algorithmic}
\end{algorithm}


\subsection{区间合并算法}
\label{section 4.15}
时序数据压缩算法CompresInterval先对每一分量的相关数据进行初始化，在我们依次读入每条数据之后，对于每条数据我们都逐渐更新最大值最小值，根据读入值
的大小我们判断是否需要开辟一个新的区间，如果不需要开辟新的区间我们将直接对最后一个区间进行扩展，当处理完每条输入的数据之后，此时根据我们事先设定的
CP(d$_{I}$)来判断区间内部数据的值是否达到了极限，当区间内部的数据点超过我们设定的值后，我们就可以使用区间合并算法来生成新的数据。对应的区间合并算法如下所示：

\begin{algorithm}
% enter the algorithm environment
\caption{区间合并算法IntervalMerge}
% give the algorithm a caption
\label{alg2}
% and a label for \ref{} commands later
\begin{algorithmic}[1]
% enter the algorithmic environment
\REQUIRE 需要合并前的区间列表IL(D$_{i}$),CP(D$_{i}$),Grad(D$_{i}$) 
\ENSURE 通过合并算法之后产生的新的区间列表

\FOR{($i=1$ to N)}
\STATE Max(D$_{i}$)=0;Min(D$_{i}$)=0;IL(D$_{i}$)=[];
\STATE Grad(D$_{i}$)=CP(D$_{}i$)*k;
\ENDFOR
\WHILE{(未达到输入数据D结束位置，且下一条数据记录为D$_{t}$)}
\STATE 	{\FOR{$i=1$ to $N$}
		\STATE Max(D$_{i}$)=MAX(Max(D$_{i}$),d$_{it}$);
		\STATE Min(D$_{i}$)=MIN(Min(D$_{i}$),d$_{it}$);
		\STATE I$_{last}$=IL(D$_{i}$)的最后一个区间；
		\IF{($ d_{it} \geq I_{last} \times v_{min}  \AND d_{it} \leq I_{last} \times v_{max} )$}
		\STATE $ I_{last} = EI(I_{last},d_{it}) $
		\ELSE  
		\STATE $ IL(D_{i}) push EC(d_{it}) $
		\ENDIF
		\IF{($   |IL(D_{i})|  > CP(D{i})   $)}
		\STATE $ IL(D_{i})=MergeInternal(IL(D_{i}),CP(D_{i}),Grad(D_{i})) $
		\ENDIF
		\ENDFOR
		}
\ENDWHILE
\STATE IL=[$ IL(D_{1}),IL(D_{2}...IL(D_{n}) $];
\RETURN GenData(IL);
\end{algorithmic}
\end{algorithm}


\section{时序数据可视化}
\label{section 4.2}

可视化部分
